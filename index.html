<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Zifan (Eric) Zhao</title>
    <link rel="icon" href="favicon.png" type="image/png">
    <style>
        body {
            font-family: sans-serif;
        }
        .name {
            font-size: 2.5em;
            text-align: center;
            margin: 0.5em 0;
        }
        .pub-list {
            list-style: none;
            padding: 0;
        }
        .pub-list li {
            margin-bottom: 16px;
        }
        .pub-list hr {
            border: none;
            border-top: 1px solid #ddd;
            margin: 16px 0;
        }
        .pub-icon {
            height: 20px;
            vertical-align: middle;
            margin-right: 8px;
        }
    </style>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0;border-spacing:0;border-collapse:separate;margin:0 auto;">
    <tbody>
      <tr>
        <td>
          <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:0 auto;">
            <tbody>
              <tr>
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name">Zifan (Eric) Zhao</p>
                  <p>
                    I'm a junior undergraduate at NYU Shanghai majoring in Computer Science and Mathematics. My research interests lie in embodied intelligence, multimodal representation learning, and reinforcement learning.
                  </p>
                  <p>
                    I'm currently working with <a href="https://www.lerrelpinto.com/" target="_blank">Prof. Lerrel Pinto</a> in the General-purpose Robotics and AI Labs (GRAIL). I’m also the founding chair of <a href="https://nyush.acm.org/" target="_blank">NYUSH ACM Student Chapter</a> and organized the <a href="http://www.nyushdic.com/" target="_blank">Digital Innovation Challenge 2023</a>.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:zz4330@nyu.edu">Email</a> &nbsp;/&nbsp;
                    <a href="https://github.com/Exiam6" target="_blank">GitHub</a> &nbsp;/&nbsp;
                    <a href="https://www.linkedin.com/in/zifan-zhao-1a2984191/" target="_blank">LinkedIn</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.com/citations?user=PWVoKaoAAAAJ&hl=zh-CN&oi=sra" target="_blank">Google Scholar</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:37%;max-width:37%;vertical-align:middle;">
                  <a href="images/Photo6.jpg">
                    <img style="width:100%;max-width:100%;object-fit:cover;border-radius:50%;" alt="profile photo" src="images/Photo6.jpg">
                  </a>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- Research Section -->
          <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:0 auto;">
            <tbody>
              <tr>
                <td style="padding:16px;vertical-align:middle">
                  <h2>Research</h2>
                  <p>
                    I am interested in embodied intelligence, multimodal learning, reinforcement learning, and general-purpose robotics. My current research broadly studies how to enable robots to perceive, reason, and act in real-world environments by leveraging multi-sensory signals and large-scale learning algorithms.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- News Section -->
          <table style="width:100%;border:0;border-spacing:0 10px;border-collapse:separate;margin:0 auto;">
            <tbody>
              <tr>
                <td style="padding:16px;vertical-align:middle">
                  <h2>News</h2>
                  <ul>
                    <li><strong>2025-04:</strong> One <a href="https://arxiv.org/abs/2402.03979" target="_blank">paper</a> is accepted at TMLR 2025.</li>
                    <li><strong>2024-09:</strong> One <a href="https://arxiv.org/abs/2409.04180" target="_blank">paper</a> is accepted at NeurIPS 2024. Can't wait to see everyone in Vancouver!</li>
                    <li><strong>2024-08:</strong> Our cute little TARS robot from Interstellar just made his first step! Have a look <a href="https://www.youtube.com/shorts/3q91EYxd1DA" target="_blank">here</a>!</li>
                    <li><strong>2024-06:</strong> Thanks to NYUSH AI Interest Group for inviting me to give an introductory <a href="https://www.youtube.com/watch?v=OkSow8ejX7E&t=353s" target="_blank">talk</a> on Machine Learning!</li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- Publications Section -->
          <table style="width:100%;border:0;border-spacing:0 10px;border-collapse:separate;margin:0 auto;">
            <tbody>
              <tr>
                <td style="padding:16px;vertical-align:middle">
                  <h2>Publications</h2>
                  <ul class="pub-list">
                    <li>
                      <img src="images/LS.png" alt="Label Smoothing icon" class="pub-icon">
                      <a href="https://arxiv.org/abs/2402.03979" target="_blank"><strong>Cross Entropy versus Label Smoothing: A Neural Collapse Perspective</strong></a><br>
                      Li Guo, Keith Ross, <u><b>Zifan Zhao</b></u>, George Andriopoulos, Shuyang Ling, Yufeng Xu, Zixuan Dong<br>
                      <em>TMLR 2025</em>
                    </li>
                    <hr>
                    <li>
                      <img src="images/NRC.png" alt="Neural Collapse icon" class="pub-icon">
                      <a href="https://arxiv.org/abs/2409.04180" target="_blank"><strong>The Prevalence of Neural Collapse in Neural Multivariate Regression</strong></a><br>
                      <u><b>Zifan Zhao*</b></u>, Li Guo*, George Andriopoulos*, Zixuan Dong*, Keith Ross*†<br>
                      <em>NeurIPS 2024</em>
                    </li>
                  </ul>
                  <p>* indicates equal contribution.</p>
                </td>
              </tr>
            </tbody>
          </table>

        </td>
      </tr>
    </tbody>
  </table>
</body>
</html>
